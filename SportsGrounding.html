<!DOCTYPE html>
	<html lang="en">
	<head>
		<title>SportsGrounding Dataset</title>
		<meta charset="utf-8">
	    <meta http-equiv="X-UA-Compatible" content="IE=edge">
	    <meta name="viewport" content="width=device-width, initial-scale=1.0">
	    <meta name="format-detection" content="telephone=no">
	    <meta name="apple-mobile-web-app-capable" content="yes">
	    <meta name="author" content="">
	    <meta name="keywords" content="">
	    <meta name="description" content="">

	    <link rel="stylesheet" type="text/css" href="css/normalize.css">
	    <link rel="stylesheet" type="text/css" href="fonts/icomoon/icomoon.css">
	    <link rel="stylesheet" type="text/css" href="css/vendor.css">
	    <link rel="stylesheet" type="text/css" href="style.css">
		
		<link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link href="https://fonts.googleapis.com/css2?family=Cormorant+SC:wght@400;700&family=Jost:wght@300;400;700&display=swap" rel="stylesheet">

		<!-- script
		================================================== -->
		<script src="js/modernizr.js"></script>


	</head>

<body>

<div id="header-wrap">
	<header id="header">
		<div class="container">
			<div class="inner-content">
				<div class="grid">
					<div class="main-logo">
						<a href="index.html"><img src="pics/sv.png" alt="logo"></a>
					</div>

					<nav id="navbar">
						<div class="main-menu">
							<ul class="menu-list">
								<li class="menu-item"><a href="index.html" data-effect="Home">Home</a></li>
								<li class="menu-item"><a href="SportsAction.html" data-effect="About">SportsAction</a></li>
								<li class="menu-item"><a href="SportsMOT.html" data-effect="Services">SportsMOT</a></li>
								<li class="menu-item"><a href="SportsHHI.html" data-effect="Projects">SportsHHI</a></li>
								<li class="menu-item"><a href="SportsShot.html" data-effect="Latest Blog">SportsShot</a></li>
								<li class="menu-item active"><a href="SportsGrounding.html" class="active" data-effect="Testimonial">SportsGrounding</a></li>
								<!-- <li class="menu-item "><a href="https://templatesjungle.gumroad.com/l/creatify-digital-marketing-website-template" class="nav-link" > <b> GET PRO </b> </a></li> -->
							</ul>

							<div class="hamburger">
				                <span class="bar"></span>
				                <span class="bar"></span>
				                <span class="bar"></span>
				            </div>
						</div>											
					
						<!-- <a href="#" class="btn-hvr-effect">
							<span>Let's Talk</span>
							<i class="icon icon-long-arrow-right"></i>
						</a> -->
						<!--search-bar-->

					</nav>

				</div>
			</div>
		</div>
	</header>		
</div><!--header-wrap-->

<section id="billboard">
	<div class="main-banner pattern-overlay">
		<div class="banner-content" data-aos="fade-up">
			<h3 class="banner-title">SportsGrounding Dataset</h3>
		    <h2 class="section-subtitle ">SportsGrounding: A Multi-Person Dataset for Spatio-temporal Video Grounding in Sports Videos</h2>
			<p>✉<a href="">Runyu He</a> &ensp; ✉<a href="">Hanxiao Xie</a> &ensp; ✉<a href="http://wanglimin.github.io/">Limin Wang</a></p>
			<div style="height: 20px;"></div>
			<p><a href="http://mcg.nju.edu.cn/en/index.html">MCG Group @ Nanjing University</a></p>
			<div class="btn-wrap">
				<a href="" class="btn-accent">paper</a>
				<a href="" class="btn-accent">github</a>
			</div>
		</div><!--banner-content-->
		<figure>
			<div style="height: 20px;"></div>
			<img src="pics/sg1.png" alt="banner" class="banner-image">
			<!-- <div style="height: 20px;"></div> -->
			<!-- <small>Compared with three relation instances from VidVRD and AG datasets showed in the upper row, the bottom row shows interaction annotations in two sample keyframes of <i>SportsHHI</i>. The bounding boxes and interaction annotation of the same instance are displayed in the same color. <i>SportsHHI</i> provides complex multi-person scenes where various interactions between human pairs occur concurrently. It focuses on high-level interactions that require detailed spatio-temporal context reasoning.</small> -->
		</figure> 
	</div>
</section>

<button id="scrollToTopBtn">Top</button>

<section id="about">
	<div class="container">
		<div class="row">
			<div class="inner-content">
				<div class="abstract-entry" data-aos="fade-up">
						<div class="section-header">
							<!-- <h2 class="section-subtitle liner">About Us</h2> -->
							<h3 class="section-title">Abstract</h3>
						</div>

						<div class="detail-wrap">
							<p>Given natural language queries and video clips, spatio-temporal video grounding task aims to output the most relevant segments and locate the corresponding regions in video clips. However, existing datasets have limited content regarding human actions and do not cover multi-person scenes. In this work, we propose a spatio-temporal video grounding dataset for sports videos, coined as <i>SportsGrounding</i>. We analyze the important components for constructing a realistic and challenging dataset for spatio-temporal video grounding by proposing two criteria: (1) grounding in multi-person scenes and motion-dependent contexts, and (2) well-defined boundaries. Based on these guidelines, we build the SportsGrounding v1.0 dataset by collecting 526 video clips of basketball category and annotating 4,479 instances with 113k bounding boxes. To benchmark this dataset, we adapt several baseline methods and provide an in-depth analysis of the results. We hope that our SportsGrounding will contribute to advancements in future methods in this field.</p>
						</div><!--description-->
				</div>
			</div><!--inner-content-->		
		</div>
	</div>
</section>


<!-- <section id="about">
	<div class="container">
		<div class="row">
			<div class="inner-content">
				<div class="abstract-entry" data-aos="fade-up">
						<div class="section-header">
							<h3 class="section-title">Demo Video</h3>
						</div>

						<div class="detail-wrap">
							<p>Please choose "1080P" for better experience.</p>
						</div>
						<div class="iframe-container">
							<iframe width="560" height="315" src="https://www.youtube.com/embed/2wbjsyg5zbI?si=1YulS2feGlWT-Vpe" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
						</div>
						<div style="height: 20px;"></div>
						<div class="iframe-container">
							<iframe width="560" height="315" src="https://www.youtube.com/embed/C6QLjN7oVwA?si=LxLxbb3HitTsJiRI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
						</div>
						<div style="height: 20px;"></div>
						<div class="iframe-container">
							<iframe width="560" height="315" src="https://www.youtube.com/embed/GxP0F2yhQhU?si=rI1VBoJOCaPVGNCq" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
						</div>
						<div style="height: 20px;"></div>
						<div class="iframe-container">
							<iframe width="560" height="315" src="https://www.youtube.com/embed/dlRZDiSTdyU?si=OTzUTvNQgxDSNuXs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
						</div>
				</div>
			</div>
		</div>
	</div>
</section> -->


<section id="about">
	<div class="container">
		<div class="row">
			<div class="inner-content">
				<div class="abstract-entry" data-aos="fade-up">
						<div class="section-header">
							<h3 class="section-title">Data Construction</h3>
						</div>

						<div class="detail-wrap">
							<p>We provide 526 sports clips in the basketball category, utilizing video data from the MultiSports dataset, which are collected from the Olympic Games, NCAA Championship, and NBA on YouTube. We merge adjacent annotated instances of the same subject and provide corresponding natural language descriptions. These descriptions are unique throughout the video clip and clearly describe the visual attributes of the subjects (such as clothing, position, etc.), actions, and relationships, while also encouraging the interaction descriptions involving other individuals and relevant subjects on the court.</p>
						</div>
				</div>
			</div>	
		</div>
	</div>
</section>


<section id="about">
	<div class="container">
		<div class="row">
			<div class="inner-content">
				<div class="abstract-entry" data-aos="fade-up">
						<div class="section-header">
							<!-- <h2 class="section-subtitle liner">About Us</h2> -->
							<h3 class="section-title">Dataset Statistics</h3>
						</div>

						<div class="detail-wrap">
							<h2 class="section-subtitle liner">Overall comparison of statistics between existing spatio-temporal video grounding datasets and our SportsGrounding v1.0</h2>
						</div>
						<figure>
							<img src="pics/sg2.png" alt="category" style="width: 65%; height: auto;">
						</figure>
						<div style="height: 20px;"></div>
						<div class="detail-wrap">
							<p>The SportsGrounding dataset retains the uncut original long video data, with the number of complete videos associated with the annotated instances comparable to that of the HC-STVG dataset. Both the HC-STVG and SportsGrounding datasets have the longest average description lengths, with relatively rich content. In addition to appearance and actions, the text descriptions in the SportsGrounding dataset also include interaction information between the subjects and other players, which places higher demands on the model's scene modeling capabilities.</p>
						</div>
						<div style="height: 20px;"></div>
						<div class="detail-wrap">
							<h2 class="section-subtitle liner">Duration distribution of the SportsGrounding dataset</h2>
						</div>
						<figure>
							<img src="pics/sg3.png" alt="category" style="width: 65%; height: auto;">
						</figure>
						<div class="detail-wrap">
							<p>The duration of instances in the SportsGrounding dataset ranges from approximately 0.2 seconds to over 16 seconds. Compared to the VidSTG and HC-STVG datasets, the duration differences between annotated instances in the SportsGrounding dataset are more pronounced, with generally shorter segment durations, which presents a greater challenge for spatio-temporal grounding.</p>
						</div>
				</div>
			</div>	
		</div>
	</div>
</section>


<section id="about">
	<div class="container">
		<div class="row">
			<div class="inner-content">
				<div class="abstract-entry" data-aos="fade-up">
						<div class="section-header">
							<!-- <h2 class="section-subtitle liner">About Us</h2> -->
							<h3 class="section-title">Evaluation metrics</h3>
						</div>
						<div class="detail-wrap">
							<p>We employ the m_tIoU, m_sIoU and vIoU@R as evaluation criteria. The m_tIoU is the average temporal IoU between the selected clips and ground truth clips, the m_sloU is the average spatial IoU within the true start and end frames and voU@R is the proportion of samples which vloU > R.</p>
						</div>
				</div>
			</div>	
		</div>
	</div>
</section>


<section id="about">
	<div class="container">
		<div class="row">
			<div class="inner-content">
				<div class="abstract-entry" data-aos="fade-up">
						<div class="section-header">
							<!-- <h2 class="section-subtitle liner">About Us</h2> -->
							<h3 class="section-title">Download</h3>
						</div>

						<div class="detail-wrap">
							<p>The SportsGrounding dataset will be open-sourced in the future.</p>
						</div>
						<div class="btn-wrap">
							<a href="https://huggingface.co/datasets/MCG-NJU/SportsGrounding" class="btn-accent">hugging face</a>
							<a href="https://codalab.lisn.upsaclay.fr/competitions/20996" class="btn-accent">competition</a>
						</div>
						<div style="height: 50px;"></div>
				</div>
			</div>	
		</div>
	</div>
</section>


<div id="footer-bottom">
	<div class="container">
		<div class="grid">
			<div class="copyright">
				<p>© 2024 <a href="https://mcg.nju.edu.cn/">Multimedia Computing Group, Nanjing University.</a> All rights reserved.</p>
			</div>
		</div><!--grid-->	
	</div>
</div>


	<script src="js/jquery-1.11.0.min.js"></script>
	<script src="js/plugins.js"></script>
	<script src="js/slideNav.min.js"></script>
	<script src="js/slideNav.js"></script>
	<script src="js/script.js"></script>	

</body>
</html>	